{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Customer Churn - Feature Engineering and Feature Selection\n",
    "\n",
    "With our model defined and initial preprocessing done, now its the time for Feature Engineering and Feature Selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Recording from the first notebook the possible Feature Engineering operations that can be applied:\n",
    "\n",
    "- Since we have the Salary, relate the income with Balance, Age, etc.\n",
    "- If IsActiveMember reffers to active account movement, relate the account balance with being an active member.\n",
    "- Considering Tenure is the time the customer is with the bank, it can be related to features like NumOfProducts, isActiveMember.\n",
    "- Group numerical features into categorical features: Age, CreditScore, Tenure.\n",
    "\n",
    "Putting more tough on it instead of leaving it abroad, it can be rearanged as:\n",
    "\n",
    "- Balance to Income Ratio\n",
    "- Income to Age Ratio\n",
    "- Relate IsActiveMember it with the number of Products and Tenure: 1 to 0, with 1 being Active with all products and long tenure, 0 with low products and low tenure, or just being inactive.\n",
    "- Product Tenure Score: Product of Tenure with NumOfProducts.\n",
    "- Bin CreditScore since it can be concealed within defined ranges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All new features will be created but a kind of Grid Search will be done to evaluate the impact of adding these features one by one in the space of original features until the feature space comprises all new features, obtaining the schema with best performance that will be used in the pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/interim/churn_customer_preprocessing.csv'\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619       1   42       2       0.00              1          1   \n",
       "1             608       1   41       1   83807.86              1          0   \n",
       "2             502       1   42       8  159660.80              3          1   \n",
       "3             699       1   39       1       0.00              2          0   \n",
       "4             850       1   43       2  125510.82              1          1   \n",
       "...           ...     ...  ...     ...        ...            ...        ...   \n",
       "9995          771       0   39       5       0.00              2          1   \n",
       "9996          516       0   35      10   57369.61              1          1   \n",
       "9997          709       1   36       7       0.00              1          0   \n",
       "9998          772       0   42       3   75075.31              2          1   \n",
       "9999          792       1   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  France  Germany  Spain  \n",
       "0                  1        101348.88       1       1        0      0  \n",
       "1                  1        112542.58       0       0        0      1  \n",
       "2                  0        113931.57       1       1        0      0  \n",
       "3                  0         93826.63       0       1        0      0  \n",
       "4                  1         79084.10       0       0        0      1  \n",
       "...              ...              ...     ...     ...      ...    ...  \n",
       "9995               0         96270.64       0       1        0      0  \n",
       "9996               1        101699.77       0       1        0      0  \n",
       "9997               1         42085.58       1       1        0      0  \n",
       "9998               0         92888.52       1       0        1      0  \n",
       "9999               0         38190.78       0       1        0      0  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns='Exited')\n",
    "y = df.Exited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_feature_space = list(x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fe_pipeline(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    df_copy['Balance_Income_ratio'] = df_copy['Balance'] / df_copy['EstimatedSalary']\n",
    "    df_copy['Income_Age_ratio'] = df_copy['EstimatedSalary'] / df_copy['Age']\n",
    "    df_copy['Products_Tenure_relation'] = df_copy['NumOfProducts'] * df_copy['Tenure']\n",
    "    \n",
    "    high_engagement_mask = ((df_copy['NumOfProducts'] >= 3) & (df_copy['Tenure'] >= 5))\n",
    "    mid_engagement_mask = ((df_copy['NumOfProducts'] >= 2) | (df_copy['Tenure'] >= 3))\n",
    "\n",
    "\n",
    "    df_copy['Engagement_Score'] = np.where(\n",
    "        df_copy['IsActiveMember'] == 1,\n",
    "            np.where(\n",
    "                high_engagement_mask , 1,\n",
    "                    np.where(mid_engagement_mask, 0.5, 0) \n",
    "            ),\n",
    "            0\n",
    "        )\n",
    "    \n",
    "    score_bins = [300, 580, 670, 740, 800, 870]\n",
    "    score_labels = [0, 1, 2, 3, 4]\n",
    "\n",
    "    df_copy['Credit_Score_bins'] = pd.cut(df_copy['CreditScore'], bins=score_bins, labels=score_labels, right=False).astype(int)\n",
    "    \n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = fe_pipeline(x_train)\n",
    "x_test = fe_pipeline(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_features: pd.DataFrame, y: pd.Series, skf: StratifiedKFold) -> float:\n",
    "    return cross_val_score(model, x_features, y, cv=skf, scoring='f1',error_score='raise').mean()\n",
    "\n",
    "def evaluate_feature_list(feature_performance_list: list[tuple[list[str],float]]) -> list[str]:\n",
    "    sorted_feature_list = sorted(feature_performance_list, key=lambda x: x[1], reverse=True)\n",
    "    best_feature_space = sorted_feature_list[0][0]\n",
    "    return best_feature_space\n",
    "\n",
    "def greedy_feature_selection(\n",
    "    model: XGBClassifier,\n",
    "    skf: StratifiedKFold, \n",
    "    x: pd.DataFrame,\n",
    "    y: pd.Series, \n",
    "    selected_features: list[str],\n",
    "    remaining_features: list[str]) -> list[str]: \n",
    "    # Store performance\n",
    "    feature_performance = []\n",
    "              \n",
    "    while remaining_features:\n",
    "        best_score = -np.inf\n",
    "        best_feature = None\n",
    "        best_features = selected_features.copy()\n",
    "        \n",
    "        # Evaluate the addition of each feature\n",
    "        for feature in remaining_features:\n",
    "            current_features = selected_features + [feature]\n",
    "            score = evaluate_model(model, x[current_features], y, skf)            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_feature = feature\n",
    "                best_features = current_features\n",
    "                        \n",
    "        # Add the best feature to the selected list\n",
    "        selected_features = best_features\n",
    "        remaining_features.remove(best_feature)\n",
    "        \n",
    "        # Store the result for this step\n",
    "        feature_performance.append((selected_features, best_score))\n",
    "        \n",
    "    best_feature_space = evaluate_feature_list(feature_performance)\n",
    "    \n",
    "    return best_feature_space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CreditScore',\n",
       " 'Gender',\n",
       " 'Age',\n",
       " 'Tenure',\n",
       " 'Balance',\n",
       " 'NumOfProducts',\n",
       " 'HasCrCard',\n",
       " 'IsActiveMember',\n",
       " 'EstimatedSalary',\n",
       " 'France',\n",
       " 'Germany',\n",
       " 'Spain',\n",
       " 'Products_Tenure_relation']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBClassifier()\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "new_feature_space = list(x_train.columns[-5:])\n",
    "best_feature_space = greedy_feature_selection(\n",
    "    model=xgb_model,\n",
    "    skf=skf,\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    selected_features=original_feature_space,\n",
    "    remaining_features=new_feature_space,\n",
    "    )\n",
    "\n",
    "best_feature_space   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we obtain the best feature space with the new features - or feature, in this case.\n",
    "\n",
    "Even though this can be considered a feature selection step, it was done only to the new features. A more thorough selection method should be applied to assert that only features that provide useful information to the model are used.\n",
    "\n",
    "Here a recursive feature elimination (RFE) will be utilized. It consists of iteratively removing the least important features based on model weights until the desired number of features is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFE(xgb_model, n_features_to_select=12)\n",
    "\n",
    "x_train_selected = rfe.fit_transform(x_train[best_feature_space], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_feature_space = [col for col, selected in zip(best_feature_space, rfe.support_) if selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CreditScore',\n",
       " 'Gender',\n",
       " 'Age',\n",
       " 'Balance',\n",
       " 'NumOfProducts',\n",
       " 'HasCrCard',\n",
       " 'IsActiveMember',\n",
       " 'EstimatedSalary',\n",
       " 'France',\n",
       " 'Germany',\n",
       " 'Spain',\n",
       " 'Products_Tenure_relation']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_feature_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " F1 Score: 0.5637583892617449\n",
      "Accuracy: 0.8483333333333334\n"
     ]
    }
   ],
   "source": [
    "# Model with all features\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(f' F1 Score: {f1_score(y_test, model.predict(x_test))}')\n",
    "print(f'Accuracy: {accuracy_score(y_test, model.predict(x_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " F1 Score: 0.5719806763285025\n",
      "Accuracy: 0.8523333333333334\n"
     ]
    }
   ],
   "source": [
    "# Model with selected features\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(x_train[best_feature_space], y_train)\n",
    "\n",
    "print(f' F1 Score: {f1_score(y_test, model.predict(x_test[best_feature_space]))}')\n",
    "print(f'Accuracy: {accuracy_score(y_test, model.predict(x_test[best_feature_space]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " F1 Score: 0.5575992255566312\n",
      "Accuracy: 0.8476666666666667\n"
     ]
    }
   ],
   "source": [
    "# Model with selected features via RFE\n",
    "\n",
    "model_new_features = XGBClassifier()\n",
    "model_new_features.fit(x_train[filtered_feature_space], y_train)\n",
    "\n",
    "print(f' F1 Score: {f1_score(y_test, model_new_features.predict(x_test[filtered_feature_space]))}')\n",
    "print(f'Accuracy: {accuracy_score(y_test, model_new_features.predict(x_test[filtered_feature_space]))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the application of RFE don't improve the model performance. This may happen due to the limited amount of data available or other reasons.\n",
    "\n",
    " In any case, this process helped define which features would compose the final arrangement of the data that will be used in the model. The next step now is apply hyperparameter tuning to improve the performance even further. \n",
    " \n",
    " Before that, it's useful to prepare the data to the training step. I'll also split the test data into validation and test to be used in the training step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid, x_test, y_valid, y_test = train_test_split(x_test, y_test, test_size=0.5, stratify=y_test, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[best_feature_space]\n",
    "x_valid = x_valid[best_feature_space]\n",
    "x_test = x_test[best_feature_space]\n",
    "\n",
    "training_data = {\n",
    "    'x_train': x_train,\n",
    "    'x_valid': x_valid, \n",
    "    'x_test': x_test,\n",
    "    'y_train': y_train,\n",
    "    'y_valid': y_valid, \n",
    "    'y_test': y_test,    \n",
    "}\n",
    "\n",
    "with open('../data/processed/training_data.pkl','wb') as f:\n",
    "    pickle.dump(training_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all prepared, the remaining steps are **hyperparameter tuning** and model **inference**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
