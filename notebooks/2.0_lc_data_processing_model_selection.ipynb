{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Customer Churn - Data Processing and Model Selection\n",
    "\n",
    "With the data analysis finished and with a general idea of the features its possible to move forward.\n",
    "\n",
    "It is needed to prepare the data for the model before any more specific feature engineering. \n",
    "Even though some models have particularities regarding the data they consume, there are some processing that is common to be applied in many models:\n",
    "\n",
    "- Drop or treat features with high cardinality or high variance \n",
    "- Encode categorical variables (If not using models with support for categorical features like catboost)\n",
    "- Deal with missing data\n",
    "- Apply feature scalling (depends on the model)\n",
    "\n",
    "Here it will be applied only data processing steps so a Machine Learning model may work proper, followed by the model selection for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/raw/training/Abandono_clientes.csv'\n",
    "df_raw = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Since there's no need to fill any missing data and the only categorical variables are binary (Gender) or with very few categories (Geography), it's a simple processing. Of course, in case any candidate model requires a specific processing, it will be done accordingly so.\n",
    "\n",
    "RowNumber, CustomerId and Surname won't be kept. Chance is these features will only provide noise to data and won't help in generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp = df_raw.copy()\n",
    "\n",
    "df_pp = df_pp.iloc[:, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kz/5j2pxpc51t11sgnw8bstnz380000gn/T/ipykernel_1269/1936658637.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_pp['Gender'].replace({'Male': 0, 'Female': 1}, inplace=True)\n",
      "/var/folders/kz/5j2pxpc51t11sgnw8bstnz380000gn/T/ipykernel_1269/1936658637.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_pp['Gender'].replace({'Male': 0, 'Female': 1}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_pp['Gender'].replace({'Male': 0, 'Female': 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "geography_dummies = pd.get_dummies(df_pp['Geography']).astype(int)\n",
    "df_pp = pd.concat([df_pp, geography_dummies],axis=1).drop('Geography', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619       1   42       2       0.00              1          1   \n",
       "1             608       1   41       1   83807.86              1          0   \n",
       "2             502       1   42       8  159660.80              3          1   \n",
       "3             699       1   39       1       0.00              2          0   \n",
       "4             850       1   43       2  125510.82              1          1   \n",
       "...           ...     ...  ...     ...        ...            ...        ...   \n",
       "9995          771       0   39       5       0.00              2          1   \n",
       "9996          516       0   35      10   57369.61              1          1   \n",
       "9997          709       1   36       7       0.00              1          0   \n",
       "9998          772       0   42       3   75075.31              2          1   \n",
       "9999          792       1   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  France  Germany  Spain  \n",
       "0                  1        101348.88       1       1        0      0  \n",
       "1                  1        112542.58       0       0        0      1  \n",
       "2                  0        113931.57       1       1        0      0  \n",
       "3                  0         93826.63       0       1        0      0  \n",
       "4                  1         79084.10       0       0        0      1  \n",
       "...              ...              ...     ...     ...      ...    ...  \n",
       "9995               0         96270.64       0       1        0      0  \n",
       "9996               1        101699.77       0       1        0      0  \n",
       "9997               1         42085.58       1       1        0      0  \n",
       "9998               0         92888.52       1       0        1      0  \n",
       "9999               0         38190.78       0       1        0      0  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp.to_csv('../data/interim/churn_customer_preprocessing.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "Since its a binary output problem - if a customer will churn or not - it's a **classification** problem, thus a classification algorithm must be chosen.\n",
    "\n",
    "A good practice is to use a simpler baseline model and compare it to other model candidates to see if they can top the simpler model. The chosen model to serve as a baseline is Logistic Regression model, from the family of linear models, while pick the other models from other families:\n",
    "    \n",
    "- **Non-linear models**: RandomForest and XGBoost;\n",
    "- **Distance-based models**: K-Nearest Neighbours (KNN) and Suport Vector Machines (SVM).\n",
    "\n",
    "LogisticRegression, SVM, and KNN benefit from Scalling, oposing to XGBoost and RandomForest that don't due to their inerent characteristics as tree-method models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance metric chosen for this is the **F1 Score**. \n",
    "\n",
    "The F1 score is described as the harmonic mean of the precision and recall of a classification model. \n",
    "It is defined by the following function:\n",
    "$$\n",
    "F_{1}=2*\\frac{Precision*Recall}{Precision+Recall}\n",
    "$$\n",
    "With both Precision and Recall being defined as\n",
    "$$ Precision=\\frac{TP}{TP+FP} $$\n",
    "$$ Recall=\\frac{TP}{TP+FN} $$ \n",
    "\n",
    "With $TP$ being *True Positive*, $FP$ being *False Positive*, and $FN$ being *False Negative*.\n",
    "A classifier with high recall may have low precision, meaning it captures the majority of positive classes but produces a considerable number of false positives. Hence, F1 Score is used to balance this trade-off.\n",
    "\n",
    " A high F1 Score generally indicates a well-balanced performance, demonstrating that the model can concurrently attain high precision and high recall, while A low F1 score implies that the model has trouble striking the precision x recall balance. Overall it is a robust metric that indicates whether the model managed to obtain a balanced generalization from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_pp.drop(columns='Exited')\n",
    "y = df_pp.Exited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled = pd.DataFrame(x_scaled, columns=x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.3, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = scaler.fit_transform(X=x_train)\n",
    "x_valid_scaled = scaler.transform(X=x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model = LogisticRegression(random_state=0)\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "svm_model = SVC(random_state=0)\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=0)\n",
    "xgb_model = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model: Any, x: pd.DataFrame, y: pd.Series,  skf: StratifiedKFold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)) -> list[float]:\n",
    "    cv_f1_scores = []\n",
    "    \n",
    "    for train_idx, test_idx in skf.split(x,y):\n",
    "        x_train_fold, x_test_fold = x.iloc[train_idx], x.iloc[test_idx]\n",
    "        y_train_fold, y_test_fold = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        model.fit(x_train_fold, y_train_fold)\n",
    "        model_f1_score = f1_score(y_test_fold, model.predict(x_test_fold))\n",
    "        cv_f1_scores.append(model_f1_score)\n",
    "    \n",
    "    return cv_f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "cv_f1_scores_logistic = cross_validation(model=log_reg_model, x=x_scaled,y=y)\n",
    "cv_f1_scores_rf = cross_validation(model=rf_model, x=x, y=y)\n",
    "cv_f1_scores_xgb = cross_validation(model=xgb_model, x=x, y=y)\n",
    "cv_f1_scores_knn = cross_validation(model=knn_model, x=x_scaled, y=y)\n",
    "cv_f1_scores_svm = cross_validation(model=svm_model, x=x_scaled, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_dict = {\n",
    "    'logistic_reg':{'max_score': max(cv_f1_scores_logistic), 'min_score': min(cv_f1_scores_logistic), 'avg_score': np.mean(cv_f1_scores_logistic), 'std_score': np.std(cv_f1_scores_logistic)},\n",
    "    'random_forest':{'max_score': max(cv_f1_scores_rf), 'min_score': min(cv_f1_scores_rf), 'avg_score': np.mean(cv_f1_scores_rf), 'std_score': np.std(cv_f1_scores_rf)},\n",
    "    'xgboost':{'max_score': max(cv_f1_scores_xgb), 'min_score': min(cv_f1_scores_xgb), 'avg_score': np.mean(cv_f1_scores_xgb), 'std_score': np.std(cv_f1_scores_xgb)},\n",
    "    'knn':{'max_score': max(cv_f1_scores_knn), 'min_score': min(cv_f1_scores_knn), 'avg_score': np.mean(cv_f1_scores_knn), 'std_score': np.std(cv_f1_scores_knn)},\n",
    "    'svm':{'max_score': max(cv_f1_scores_svm), 'min_score': min(cv_f1_scores_svm), 'avg_score': np.mean(cv_f1_scores_svm), 'std_score': np.std(cv_f1_scores_svm)},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logistic_reg</th>\n",
       "      <th>random_forest</th>\n",
       "      <th>xgboost</th>\n",
       "      <th>knn</th>\n",
       "      <th>svm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>max_score</th>\n",
       "      <td>0.367491</td>\n",
       "      <td>0.634731</td>\n",
       "      <td>0.623229</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_score</th>\n",
       "      <td>0.229630</td>\n",
       "      <td>0.518987</td>\n",
       "      <td>0.534535</td>\n",
       "      <td>0.440895</td>\n",
       "      <td>0.481356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_score</th>\n",
       "      <td>0.314076</td>\n",
       "      <td>0.571552</td>\n",
       "      <td>0.573204</td>\n",
       "      <td>0.474631</td>\n",
       "      <td>0.524926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score</th>\n",
       "      <td>0.040593</td>\n",
       "      <td>0.031971</td>\n",
       "      <td>0.022340</td>\n",
       "      <td>0.023806</td>\n",
       "      <td>0.028779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           logistic_reg  random_forest   xgboost       knn       svm\n",
       "max_score      0.367491       0.634731  0.623229  0.517241  0.578947\n",
       "min_score      0.229630       0.518987  0.534535  0.440895  0.481356\n",
       "avg_score      0.314076       0.571552  0.573204  0.474631  0.524926\n",
       "std_score      0.040593       0.031971  0.022340  0.023806  0.028779"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cross_val_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best models where the Random Forest and XGBoost, both with similar performance. Still, all models presents a better result than the baseline logistic regression model. \n",
    "\n",
    "Another simpler approach could be use a random binary generator, to check whether the models can surpass its performance. \n",
    "\n",
    "Let's follow comparing the ensemble models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model.fit(x_train, y_train)\n",
    "xgb_model.fit(x_train, y_train)\n",
    "\n",
    "rf_preds = rf_model.predict(x_valid)\n",
    "xgb_preds = xgb_model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_accuracy = accuracy_score(y_valid, rf_preds)\n",
    "xgb_accuracy = accuracy_score(y_valid, xgb_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.857\n",
      "XGBoost Accuracy: 0.850\n"
     ]
    }
   ],
   "source": [
    "print(f'Random Forest Accuracy: {rf_accuracy:.03f}')\n",
    "print(f'XGBoost Accuracy: {xgb_accuracy:.03f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classif_report = classification_report(y_valid, rf_preds)\n",
    "xgb_classif_report = classification_report(y_valid, xgb_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91      2389\n",
      "           1       0.75      0.45      0.56       611\n",
      "\n",
      "    accuracy                           0.86      3000\n",
      "   macro avg       0.81      0.70      0.74      3000\n",
      "weighted avg       0.85      0.86      0.84      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rf_classif_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91      2389\n",
      "           1       0.69      0.47      0.56       611\n",
      "\n",
      "    accuracy                           0.85      3000\n",
      "   macro avg       0.78      0.71      0.74      3000\n",
      "weighted avg       0.84      0.85      0.84      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(xgb_classif_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the analysis, both models perform very similarly, with XGBoost performing slightly worse in Accuracy and Precision than RandomForest. The choice now relies on the inner characteristics of each model:\n",
    "\n",
    "- Random Forest is a bagging model, in which it build its trees in parallel, with the choice being an average of the tree outputs, which can lead to a higher accuracy, but tendency to overfitting in real-life scenarios. \n",
    "- XGBoost is a boosting model, in which its trees are built sequentially, which the subsequent tree working on the rights and wrongs of the previous tree. Due to its regularization techniques it seeks to avoid overfitting and perform better in real-life scenarios.\n",
    "\n",
    "Based on that, both models would perform well for this task. In this case, I'll pick XGBoost due to being more knowledgeable of this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the model selected, now for **Feature Engineering and Feature Selection**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
